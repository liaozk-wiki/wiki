---
layout: post
title: 数据库相关知识
category: 计算机
---

# 数据库的整体概览
<br>
数据：符号记录
<br>

数据库：存放数据的仓库，有组织的数据集合（有组织-数据结构）
<br>

数据库管理系统：软件系统，mysql，postgressql，redis，clickhouse，mongodb
<br>

数据模型：现实世界的数据特征抽象   可大致分为

1. 概念模型：现实事物的抽象（实体，属性，码，实体型（表结构），实体集（表），联系）
2. 逻辑模型：层次模型，网状模型，关系模型，面向对象数据模型，对象关系模型
3. 物理模型：mysql是以b+树的形式组织存储数据

<br>

数据模型的基本要素：

1. 数据结构
2. 数据操作
3. 数据完整性约束

<br>

可以从这三个角度去分析所有的数据库，其在不同数据库中的实现。
<br>

1. 外模式：视图
2. 模式：全体数据的逻辑结构和特征描述（关系，k-v）
3. 内模式：物理结构和存储方式的描述（b+树，页）

<br>

数据库是什么？数据库的通用特征是什么？这些通用特征在不同数据库软件中是如何实现？
<br>

关系型数据库，nosql非关系型数据库，newsql，非关系型数据库增加事务，sql语言的支持。



## 数据库基本构成



<img src="https://cdn.jsdelivr.net/gh/liaozk-wiki/md_img/md/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%80%E8%88%AC%E7%BB%93%E6%9E%84.jpg" alt="数据库一般结构" style="zoom:50%;" />





![image-20230331234602168](https://cdn.jsdelivr.net/gh/liaozk-wiki/md_img/md/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%93%E6%9E%841.png)

<br>

## 进程模型
<br>
DBMS客户端
<br>



DBMS工作者

1. 每个工作者拥有一个进程
2. 每个工作者拥有一个线程
3. 线程池分配给工作者



当系统负载过高时应当，有准入控制，准入控制一般为：

1. 控制连接数
2. 优化器来决定是否推迟执行查询

<br>

上述模型都试图独立处理客户端请求，但每个工作者都是共享同一个数据库，sql请求都需要交给服务器处理，结果也均需要返回给客户端，就涉及到缓冲区



<img src="https://cdn.jsdelivr.net/gh/liaozk-wiki/md_img/md/%E7%BC%93%E5%86%B2%E5%8C%BA.jpg" alt="缓冲区" style="zoom:50%;" />







## 并行架构
1.共享内存：当前每一台电脑都算是

<img src="https://cdn.jsdelivr.net/gh/liaozk-wiki/md_img/md/%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E6%9E%B6%E6%9E%84.jpg" alt="共享内存架构" style="zoom:50%;" />



<br>

2.无共享：多个独立计算机集群，没有共享硬件，dbms负责集成；

独立集群，水平分区，跨处理器协调事务，分布式死锁检测，两阶段提交

故障：1个节点故障，全体停机；数据跳跃；冗余（链式分簇，全数据冗余）

<img src="https://cdn.jsdelivr.net/gh/liaozk-wiki/md_img/md/%E6%97%A0%E5%85%B1%E4%BA%AB%E6%9E%B6%E6%9E%84.jpg" alt="无共享架构" style="zoom:50%;" />

<br>

3.共享磁盘：挂了一个，不影响使用

<img src="https://cdn.jsdelivr.net/gh/liaozk-wiki/md_img/md/%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9E%B6%E6%9E%84.jpg" alt="共享磁盘架构" style="zoom:50%;" />

<br>

4.非均衡内存访问non-uniform memory access
<br>



## 关系查询处理器
<br>

1. 查询的解析与授权：语法检查，名称处理（服务器.库.模式.表），转义，权限检查
2. 查询重写
   1. 视图重写；
   2. 常量运算；
   3. 谓词逻辑重写；
   4. 语义优化；
   5. 子查询平面化或者其他启发式重写；对于mysl而言，查看优化后的实际执行语句（explain sql；show warings；注意要同时执行）
3. 查询优化：选择走那个索引，如何join等具体的执行计划
4. 查询执行：没搞懂
5. 访问方法：对系统支持的基于磁盘的数据结构的访问进行管理（实际访问数据磁盘）
6. 数据仓库：这个偏大数据，1:位图索引；2:快速加载；3:物化视图（区别与mysql的逻辑视图）；4:olap与ad-hoc 查询（即席查询，类似自定义查询）；5:雪花模式查询优化（一个事实表，一堆的通过外键关联的维度表）6:数据扩展，支持更多的数据类型，抽象结构（对数据类型的抽象）类型等
   <br>

## 额外单独提一下日志
在实际的开发过程中，几乎不会碰到日志（碰到一般也是要去找DBA🤣），但是作为关系型数据库，日志是其相当重要的一个模块。这里面蕴含的对问题的解决方案还是挺有意思的（后来发觉这个与[操作系统中的持久化](https://liaozk.wiki/man_complete/os/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F_%E6%8C%81%E4%B9%85%E5%8C%96#%E5%B4%A9%E6%BA%83%E4%B8%80%E8%87%B4%E6%80%A7-fsck%E6%97%A5%E5%BF%97)异曲同工）。

<br>

为了提升性能，数据库把修改保存到缓冲区，一但崩溃，将会造成缓冲区数据丢失，只记录了事务部分数据，破坏了原子性；为了解决这个问题：

1. 影子副本：事务创建一个数据副本，提交的时候用副本替换原始数据；
2. 日志管理：所有的修改记录到日志，提交后再统一刷新到磁盘

<br>

日志的主要作用：保持已提交事务的持久性，协助事务的回滚及原子性，崩溃恢复。

<br>

就mysql而言持久性可以理解为binlog，原子性则在于一个事务的日志一定是记录在一起的，要么有事务的全部日志要么一条都没有，崩溃恢复则依赖于redolog与binlog的配合。

<br>

WAL(Write-Ahead Logging，预写日志)协议：

1. 对数据库页的更新会产生一条日志记录，在页被刷新到磁盘前，日志先于被刷新到日志系统。
2. 日志记录按顺序刷新，一条被刷新了，保证其之前的都已被刷新。
3. 事务提交返回成功之前，日志必须被刷新到日志设备。



<img src="/Users/liaozk/Downloads/数据更新与日志.jpg" alt="数据更新与日志" style="zoom:50%;" />

总结就是：日志落盘后再更新内存数据页，最后再异步将数据持久化到磁盘

对于mysql：

```sql
BEGIN;
UPDATE accounts SET balance = 1000 WHERE id = 1;
COMMIT;
```

执行流程：

1. **生成 undo log** :“原值：balance=500” → 用于回滚或 MVCC
2. **修改内存数据页**: balance = 1000
3. **生成 redo log**: “Page X, Set balance=1000” → 写入 log buffer
4. **写 binlog**（事务提交时）: 记录 `UPDATE ...` 或行变更
5. **redo log 落盘**（fsync）: 确保持久性
6. **binlog 落盘**（可选 fsync）: 确保复制安全
7. **事务提交成功**
8. **后台异步刷脏页**

<br>

**两阶段提交（2PC）**：
为了保证 redo log 和 binlog 一致性，MySQL 使用 **两阶段提交**：

- `prepare`：redo log 写入并标记为 prepare 状态
- `commit`：binlog 写入，再将 redo log 标记为 commit





aries协议：略

<br>

# 关系型数据库
<br>



## 关系型数据库的一些理论
<br>
一些概念：

- 属性：列的名字
- 依赖：属性间的关系
- 元组：一行数据
- 表：一个具体的关系
- 域：数据类型（int，bigint，decimal...）
- 键：码
- 候选键：候选码
- 超键：超码
- 外键：一个关系的键依赖另一个关系的键
- 主属性：所有码的属性
- 候选码-主码-全码
- 笛卡尔积
- 投影：列
- 选择：行
- 自然连接
- 外连接
- 内连接
- 除法
- 函数依赖：x->y     x函数确定y
- 非平凡函数依赖：x->y 同时 y不属于x
- 平凡函数依赖：x->y 同时 y属于x：100%成立。（a,b）->a
- 完全函数依赖：x->y 对x的任意真子集都不成立
- 部分函数依赖：
- 传递函数依赖：
- 关系数据模型：关系数据结构+操作+完整性约束
- 关系是关系模式的一个具体实现（类与对象的关系）
- 关系模式：R(U,D, DOM,F)；属性+域+属性与域的映射+完整性约束
- 关系操作：SQL
- 完整性约束：
  - 实体完整（主键不为null）
  - 参照完整（外键null/必须为被参照关系的码）
  - 自定义完整性
- 范式：
  - 1nf：属性不可分
  - 2nf：非主属性，完全函数依赖于键码，即消除非主属性对码的部分函数依赖
  - 关系 （学生，课程）->系。实际上 课程->系
  - 3nf：不存在非主属性，传递函数依赖于码，即消除非主属性对码的传递函数依赖:学号->系->宿舍。学号->宿舍
  - 下面的就不太懂了：
  - bcnf：关系存在非平凡函数依赖x->y，则x必定包含码
  - 多值依赖：
  - 4nf：
  - 公理系统，模式分解 等等

<br>

这里提到的这些，一般日常的开发中很少用到，但是关系型数据库是有着严密的数学基础理论的，从学习的角度，程序是现实的抽象，理论则是抽象中的抽象了。
<br>

数据库的通用并发控制：
<br>

事务是并发控制的基本单位；
<br>

可串行化调度：保持冲突操作次序不变的情况下，调整非冲突操作次序，从而得到串行调度，则此调度属于可串行化调度。

<br>

<img src="https://cdn.jsdelivr.net/gh/liaozk-wiki/md_img/md/%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6.jpg" alt="并发控制" style="zoom:50%;" />





## 关系型数据库的基本构建
<br>

## 以mysql为例对关系型数据库的深入理解
一般sql的逻辑执行顺序：

```sql
1. FROM / JOIN        → 先确定数据源（包括 JOIN）
2. WHERE              → 对数据进行条件过滤
3. GROUP BY           → 分组（如果有）
4. HAVING             → 对分组结果过滤（如果有）
5. SELECT             → 选择要返回的字段
6. DISTINCT           → 去重（如果有）
7. ORDER BY           → 排序
8. LIMIT / OFFSET     → 限制返回行数
```

实际物理执行时，涉及到：

1. 谓词下推：where条件提前，甚至join时就过滤
2. 索引下推：扫描表时就将部分where条件应用了
3. 其他...





### 一条查询语句的流程



<img src="https://cdn.jsdelivr.net/gh/liaozk-wiki/md_img/md/%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B.jpg" alt="查询语句执行过程" style="zoom: 33%;" />

1. 一般是系统通过连接池与mysql建立连接（连接管理），这里会读取权限。
2. mysql内部也会通过连接池分配一个线程（工作者）处理次连接（线程管理）
3. sql语句首先会词法分析，表别名，列名等被处理；语法分析，是否存在语法错误；然后就是优化器转化为优化后的可执行的语句，并确定执行计划等（查询处理器)
4. 执行器调用接口读取数据，这里涉及页加载到buffer pool中
5. 执行器从引擎读取的元组，被保存在net buffer中，存满了就调用socket 接口 发送出去，然后清空继续。所以全表扫描不会打爆内存。



关于net buffer的补充：

net buffer 大小由net_buffer_length 定义，同时因为是边读边发，所以网络也会影响事务的执行时间。sending to client 表示netbuffer 满了，等待客户端接受；sending data则是表示语句正在执行。
<br>

### 一条更新语句的流程

<img src="https://cdn.jsdelivr.net/gh/liaozk-wiki/md_img/md/%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B.jpg" alt="更新语句执行过程" style="zoom:33%;" />

两阶段提交:
<br>
redo log:
<br>
innodb引擎特有，记录的是物理日志，循环写（write pos，check point）；
<br>
redo log buffer--page cache -- 磁盘
<br>
innodb_flush_log_at_trx_commit：

1. 事务提交，留在redolog buffer
2. 事务提交，持久化到磁盘
3. 事务提交写到page cache



持久化：
<br>

1. 有一个后台线程，负责将 redolog buffer write到page cache 然后fsyn到磁盘
2. redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。
3. 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。



<br>

组提交：

<br>

lsn：日志逻辑序列号，每次写盘会保证小于返回的lsn的日志都被写盘。

<br>

binlog：

mysql，servser所有

binlog cache-- write binlog文件-- fsyn磁盘

binlog cache 是按照线程分配

sync_binlog：

​	0:每次事务提交只write 不fsyn
<br>
​	1:每次事务提交都fsyn
<br>
​	n：每次事务提交都write，积累n个才fsyn

<br>

先写redolog标记为 prepare状态 
<br>

再写binlog
<br>

最后再更新redolog为commit
<br>

change buffer
<br>

一条语句的更新流程：

1. 执行器
2. 内存有就更新内存，内存没有就写入change buffer 
3. 写redolog
4. 写binlog
5. commit redolog
6. changebuffer 会异步加载并更新为脏页，脏页会由后台线程异步刷新到磁盘；



刷脏页：

1. redolog 写满了；
2. 内存不足了；
3. 有空闲
4. 关机



对一一个长时间使用的库来说，未被使用的页面极少；
<br>

innodb_io_capacity：告诉mysql 磁盘能力
<br>

刷盘速度：

<br>

1. 所允许的脏页比例

2. redolog 写盘速度（刷即意味着事务提交了，此时日志一定先写好了)
3. 如果一个查询，需要读取大量页，可能导致已有脏页刷盘，从而影响速度。



### 索引

对于mysql而言，关系是以b+树形式组织的；索引可以理解为依赖于这个关系的另外一张b+树结构组织的关系。只不过其叶子节点保存的是主键id；因为其是b+树所以查找的时间复杂度只有O(log(N）因为其叶子节点只存有id，所以空间相对较小。alert table t engine=innodb，可以整理表。
<br>

常见索引结构：
<br>

kv-hash：等值查询快，无法范围查询；
<br>

有序数组：等值及范围都比较快，但是维护比较难，向中间插入一条数据会移动整个列；
<br>

b+树：
<br>

覆盖索引：不需要回表
<br>

最左前缀：1.字符串匹配；2.联合索引（a,b,c）等效a,b,c,bc
<br>

索引下推：通过索引筛选主键时，已经将where条件进行了过滤
<br>

普通索引与唯一索引：

1. 查找：唯一索引找到就不需要再找下一个了，普通索引还需要找下一个；
2. 更新：唯一索引需要判断唯一性，必须要把数据读入内存，故更新的时候没法使用change buffer，而普通索引可以。

所以，如果业务层可以保证唯一性，最好使用普通索引。
<br>

为何会选错索引：
<br>

优化器一般是基于代价选择索引，而代价一般由（扫描行数+是否使用临时表+排序等决定），其中扫描行数在innodb中基于抽样统计

<br>

基数cardinality：索引上不同值的个数
<br>

采样统计：数据页数量*n个页面的平均；当对表的改动行数超过1/m时，触发重新统计；
<br>

n与m：innodb_stats_persistent，on：统计信息存储到磁盘，默认n20，m10；off 内存，n8，m16；
<br>

可能统计信息出错，analyze table 重新统计；
<br>

sql不走索引：
<br>

因为是b+树结构存储，如果对字段有函数操作，则无法走索引，因为无法得知函数操作之后的结果，只能全表扫描，逐一应用函数。

1. 函数操作
2. 隐式的数据类型转换，等同于：cast（xxx as signed int)
3. 隐式的字符集转换，等同于：convert(xxx using utf8mb4)

字符串加索引：

alter table add index i_emali(email(6));

1. 一旦使用前缀索引，覆盖索引将会失效，因为要回表进一步判断
2. reverse
3. hash



<br>

### 排序的原理
Using filesort  mysql会给每个线程分配一块儿 sort buffer（sort_buffer_size），所需要排序的数据大于 filesort buffer 排序会借助磁盘（大量数据排序会因为磁盘IO减慢速度）

<br>

排序实现方式:

1. 全字段排序：需要的字段放进sort buffer，排好序后返回结果。
2. rowid排序：排序字段加id，排好序后再主键回表。



如果不能走索引（索引天然有序），一旦数据量大，排序将会非常耗时；订单系统中很多页面的查询，会依据createtime排序，随着数据量的增加后续越来越慢，此时一般可以用主键id替换。
<br>

### join的原理
<br>
其实对于关系型数据库而言，join本就是其一大特色，如果能走索引，可以多关联几张表。

1. Index Nested-Loop Join
   1. 从表 t1 中读入一行数据 R；
   2. 从数据行 R 中，取出 a 字段到表 t2 里去查找；
   3. 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；
   4. 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。
2. Simple Nested-Loop Join：同上只是驱动表中t1中的一行数据R需要遍历被驱动表t2全部数据
3. 对2的稍微优化：Block Nested-Loop Join，join buffer，将小表放到内存的join buffer，减少IO次数，放不下就只存放一部分。



<br>

一般说的小表：各自where条件过滤完后参与join的各个字段数据量小的表，数据量小，意味着相同内存空间可以存放更多的数据。减少io次数。
<br>
Multi-range read：id放在read_rnd_buffer中，再将id排序，依据排序后的数组再到主键索引中查找；通过排序尽量避免随机读（原本满足条件的id可能比较分散）。
<br>
set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
<br>
在inj算法中使用join buffer 就是bka算法，不是一条一条去被驱动表索引找，而是一次在内存中读n条，然后去匹配。
<br>

### 事务-锁与mvcc
<br>
关于隔离级别的相关信息此处不再过多介绍，mysql 并发控制的实现是采用了，锁+mvcc
<br>

mysql mvcc 快照读：

1. 事务启动时维护了一个活跃事务id数组
2. 数组中最小的id=低水位；系统中最大的事务id+1=高水位；
3. 小于低水位-可见；低水位到高水位之间，不再数组内就可见（我这个事务启动时系统正在执行的最小id=1，最大id=9，其中id2～8已经执行完了，我的数组是[1,9]，读取数据A=10（trxid=8），可见）；大于高水位，不可见；

<br>

rr隔离级别
<br>

1. mysql 加锁的基本单位是next-key lock；next-key 由 行锁+间隙锁；
2. 查找过程中，访问到的行就会加锁；
3. 唯一索引的等值查询，会退化为行锁；
4. 普通索引上的等值查询，最后一个不满足会 退化为为间隙锁



mysql读取数据只涉及 元数据锁；对表的CRUD都会涉及到元数据锁
<br>

更新等则会加写锁；
<br>

按照锁理论，写锁是独占锁，mysql为了保证写读不冲突，在加了写锁的情况下还能读取，则是依赖于mvcc；
<br>

rc隔离级别则没有间隙锁

<br>

```sql
update 表A set 字段B=1 where 条件C
```

C上有索引：

1. matadata锁
2. 索引上**扫描到**行的next-key锁
3. 回表主键记录**匹配行**的record锁（排他锁）

C上无索引：

1. matadata锁
2. 主键上所有扫描到**且匹配**的行record锁（排他锁）





Mysql的行级别锁：
![image-20250810165039895](https://cdn.jsdelivr.net/gh/liaozk-wiki/md_img/md/image-20250810165039895.png)



共享锁，基本用不到，除非显示的使用 lock in share model；因为普通的select mvcc 不需要加锁。





<br>

### 主备一致性
<br>



### Mysql 其他特性
<br>
表空间回收：
<br>
mysql 8.0之后，允许表结构放在系统表空间的 
<br>
innodb_file_per_table：on 以idb的形式存放表结构，而不是共享表空间
<br>
mysql 删除数据 delete，只是将页/页空间标记为空闲，而不是实实在在的回收表空间。
<br>
页空间标记为空闲：可以存放该表的其他符合索引位置的数据；
<br>
页标记为空闲，则该页不一定只存放该表的数据可以存放其他表的；
<br>
重建表： alter table a engine=innodb;可以重新组织，回收空间；
<br>
online 与 inplace
<br>
alter table t engine=innodb,ALGORITHM=inplace;
<br>
alter table t engine=innodb,ALGORITHM=copy;
<br>
optimize table、analyze table 和 alter table 这三种方式重建表
<br>
optimize table=recreate+analyze
<br>
随机一条数据：
<br>
limit 随机数，1
<br>
id>= 随机数 limit 1
<br>



# 非关系型数据库-Redis

<br>

## data type

<br>

### 1.Strings

<br>
any strings or binary data, can`t bigger than 512MB.
<br>
some argument:

1. nx:not exist
2. xx:exist



<br>

Some operation:

1. getset
2. mset/mget (return a array of values)
3. incr(atomic)/incrby decr(atomic)/decrby
4. incrbyfloat
5. ...
   <br>

### 2.lists

<br>
Basic commands:
<br>

1. lpush/rpush
2. lpop/rpop
3. llen
4. lmove
5. ltrim
6. lrange



<br>

Blocking commands

1. blpop/brpop+expire
2. blmove/brmove



<br>

common use:

1. remember last posted by user
2. Consumer-producer



<br>

capped list: ltrim
<br>
Max: 2^32 -1 
<br>
1添加元素，key不存在则会自动创建
<br>
2移除元素，若为空着key会自动删除 stream 例外
<br>
3只读/移除 一个空的key，返回相同的结果
<br>
### 
<br>

### 3.sets

<br>
Basic  commands:

1. sadd
2. srem
3. sismember
4. sinter
5. scard
6. smembers/scan
7. sinter
8. sunionstore
9. spop/srandmember
   <br>

### 4.hash

<br>
Like java hashMap
<br>
Basic commands:

1. hset
2. hget
3. hmget
4. hincrby
   <br>

### 5.sorted-sets

<br>

Basic commands:

1. zadd
2. zrange/zrevrange.   --withscores
3. zrangebyscore
4. zremrangebyscore
5. zrank/zrevrank
   <br>

## Data Structure(object)

<br>
redisObject {

type

encoding

ptr

Lru 末次访问时间等

refcount 引用计数

}
<br>
ptr 关联着最底层的数据结构实现
<br>

## Persistence

<br>
RDB:Redis DataBase
<br>
AOF:Append only file
<br>
RDB:
<br>
触发方式-手动：

1. save 主进程
2. bgsave fork一个子进程处理



<br>

自动：

1. conf ：save m n 
2. 主从
3. debug reload
4. shut down



copy on write
<br>
实现细节：fork进程+主进程修改存的副本
<br>
AOF:
<br>
写后日志的方式
<br>

1. append
2. write
3. sync



<br>

aof-buf 写入aof文件的策略：

1. Always 同步写
2. Everysec 每秒写回
3. No 操作系统控制





aof重写，可以简化文件
<br>
auto-aof-rewrite-percentage
<br>
auto-aof-rewrite-min-size
<br>
BGREWRITEAOF 手动出发重写
<br>
RDB+AOF:
<br>
两次rdb之间，利用aof记录操作，rdb完成后再清空aof日志文件。
<br>

## pub/sub

<br>
发布/订阅
<br>
channel+pattern
<br>
重复订阅会收到两个消息
<br>

## Transaction

<br>
一组命令的集合，事务中的命令都会被序列化，会按顺序串行化执行，其他命令不会插入到其中。
<br>
一次性+顺序+排他+一系列命令
<br>
basic command:
<br>
MULTI:开启事物，随后命令放入队列
<br>
EXEC:执行
<br>
DISCARD:丢弃
<br>
WATCH:监视key，exec命令后事务实际执行前，key被其他命令修改，则事务中断，不会执行事务中的命令，最后取消watch监控的key
<br>
UNWATCH:
<br>
error：
<br>
开启事务后，语法错误，事务失败
<br>
类型错误，运行时错误，则只会跳过错误命令其他的还是会执行
<br>
wtach命令提供了check-and-set 行为
<br>
A 要么全部执行/未执行，运行错误会执行失败
<br>
C 错误整个事务都不会被提交
<br>
I 不会被其他客户端命令打断
<br>
D 不保证，rdb/aof都是异步
<br>

## 主从复制-基本原理

<br>
单向：master--slave
<br>
5.0之前：slave of  之后：replicaof
<br>

- 确立主从关系
  - replicaof master ip+port
- 全量复制+增量复制
  - 全量复制
    - Stage1:建立连接
    - Stage2:master--RDB+replication buffer,slave--RDB
    - Stage3:slave--replication buffer
  - 增量复制
    - client buffer -- replication buffer（从库专门接受命令以实现主从同步）
    - repl-backlog-buffer（从库断开后，主库的环形缓冲区）  -- replication buffer
- 基于长链接的命令传播
  <br>
  other question：
  <br>

1. 不持久化的服务器开启自动重启，可能导致全部数据丢失；不持久化重启，master情况，然后同步导致slave也清空
2. 全量复制采用RDB：成本更低
3. 无磁盘复制模式：直接dump  RDB到slave的socket
4. 主-从-从：多个slave，fork 子进程开销较大



读写分离导致的一些问题：

1. 延迟于不一致
2. 过期（惰性删除与定期删除）
3. 故障切换
   <br>

## 主从复制-Redis Sentinel

<br>
https://pdai.tech/images/db/redis/db-redis-sen-1.png
<br>

- Sentinel 集群组件
  - 新的sentinel 发布消息到master _ _ sentinel _ _:hello 频道
  - 现有sentinel订阅该频道
  - 获取新的sentinel地址与端口，建立连接组建集群
- Sentinel 监控
  - 向主库发送info命令，获取所有从库列表，建立连接监控
- 故障判断
  - 主观下线：sentinel单独判断
  - 客观下线：某个sentinel判断下线后向集群广播 is-master-down-by-addr，其他sentinel返回判断，y 大于 配置文件中的quorum 就判断为客观下线
- 故障处理
  - 集群leader选举
    - Raft算法
    - 半数以上票+大于quorum配置值
    - 假如sentinel挂了几个，可能导致大雨quorum能判断客观下线，但不满足大于半数无法选举leader
  - 新master选举
    - 过滤不健康，未回复ping的
    - slave-priority 优先级最高的
    - 复制偏移量最大的
  - 故障转移
    - 通知应用程序新master
    - 从节点 replicaof
      <br>

## Reids Cluster

<br>
难度过大，暂不考虑
<br>

## 缓存问题

<br>

### 1.缓存穿透（都没有）

<br>
缓存与数据库中都没有该数据，不停的请求，不停的查数据库，失去缓存意义。
<br>

1. 简单校验
2. 数据库取不到，key-null等
3. bloomfilter
   <br>

### 2.缓存击穿（缓存没有数据库有）

<br>
缓存没有，用户又多，瞬间数据库访问压力增大，一般是缓存到期。多指一条数据。
<br>

1. 热点数据不过期
2. 接口限流，熔断，降级
3. 互斥锁
   <br>

### 3.缓存雪崩（缓存没有，数据库有）

<br>
多指大批数据批量到期
<br>

1. 随机过期时间
2. 热点不过期
3. 分布在不同的缓存数据库中
   <br>

### 4.缓存污染

<br>
冷点数据长时间占用，缓存满了
<br>

1. 设置淘汰策略
   <br>

### 5.淘汰策略

<br>
最大缓存：CONFIG SET maxmemory 4gb；
<br>

- 4.0之后默认：noeviction  不淘汰
- 对设置了过期时间的数据进行淘汰
  - Volatile-random
  - Volatile-ttl
  - Volatile-lru
  - Volatile-lfu
    - lfu算法有一个更优的计数策略
- 全部数据进行淘汰
  - Allkeys-random
  - Allkeys-lru
  - Allkeys-lfu
    <br>

### 6.一致性

<br>
太难
<br>
https://pdai.tech/md/db/nosql-redis/db-redis-x-cache.html
<br>

## 运维监控

<br>











# 大数据，数据仓储